## 들어가면서
* 지난 글에서 Synchronization의 필요성과 개념에 대해 정리했다. Critical Section이란 여러 프로세스나 쓰레드들이 공유하는 데이터 영역에 접근하는 것을 의미한다고 했으며, Entry Section과 Exit Section을 정의하였다. 또한 Critical Section을 처리하는 데 있어서 필요한 3가지 요건(Mutual exclusion, Progess, bounded waiting)에 대해 공부했다.
* 이번 글에서는 구체적으로 Critical Section을 처리하려면 어떻게 해야하는가에 대해 Low-level 방법과 High-level에 대해서 공부하려고 한다.

---
## 1. Low-level synchronization primitve(Spinlocks)
### 1) Software-only solution
* 저번 글에서 정리했던 Synchronization의 개념 예제를 떠올려보자. Producer, Consumer가 존재하고 counter 변수를 공유하는 상황이었다.
* Software-only solution은 **Peterson's algorithm**으로 구현한다. 이 방법은 Hardware의 도움을 받지 않고 Software영역에서 Critical Section의 entry와 exit을 처리한다. 아래 예제를 보자.
```
// Process i
repeat
    flag[i] := true;
    turn := j;
    while(flag[j] and turn=j) do no-ops;
        ...
        Critical Section
        ...
    flag[i] = false;
        remainder section
until false;
```
* 위의 Peterson's algorithm은 Critical section을 처리하기 위해 필요한 3가지 요건(Mutual exclusion, Progress, bounded waiting)을 모두 충족시킨다.
* 그렇다면 어떻게 모든 조건을 충족시킬 수 있는지 자세히 생각해보자.
```
flag[i] = true;
// 프로세스 i가 먼저 Critical Section에 접근하기 위해 flag[i]를 true로 설정하여 신호를 보낸다.

turn = j;
// 프로세스 i는 내가 먼저 들어간다고 선언하고 조금 늦게 도착한 j에게 turn을 돌려준다.
// 여기까지 진행된 상태라면 j 입장에서는 flag[j] = true, turn =i일 것이다.
// 그러면 프로세스 i가 j 프로세스로 차례를 넘겨주자마자 아래의 while문을 수행하고 Critical Section에 진입할 수 있다.

while(flag[j] && turn == j);
// Critical section에 들어가기 위해서는 당연히 내 차례여야 한다.
// 따라서 내 차례이거나(turn = i), j가 Critical Section에 진입하고 싶지 않다면(flag[j] = false)
// Spinlock을 빠져나와서 Critical section에 진입할 수 있게 된다.
// 이렇게 turn과 flag 변수를 이용해서 동시 접근을 막는 것이다.
```
* 이렇게 하면 내 순서가 아니면 접근을 할 수 없게 되고 / 내 순서가 아니더라도 남들이 아무도 안 쓰면 쓸 수 있게 되고 / i 입장에서 turn은 j가 바꿔주는 것이기 때문에 critical section을 무한정 쓸 수는 없게 된다. 남이 도와줘야 하기 때문이다.
* 따라서 Peterson algorithm이 software-only solution에서는 동기화문제를 해결하는 방법이 된다.

### 2) Hardware Atomic solution
* Hardware Atomic solution은 위처럼 software 코드만으로는 동기화 문제를 해결하기에 너무 복잡하니까(프로세스가 엄청 많다고 하면 코드가 터지지 않을까?) 고안된 것이다.
* 이 방법은 **atomic instruction**을 통해서 동기화 문제를 해결하고자 하는 것인데, 크게 Test-and-Set instruction과 Swap(or xchg) instruction이 있다.
    - 1) Test-and-Set
    - * Test-and-Set instruction은 공유 데이터로 처음에 false로 초기화된 **var lock**을 사용한다. 동작 방식은 간단한데, lock 변수가 true이면 no-ops 상태여야 하고, lock 변수가 false일 때만 Critical Section에 진입할 수 있게 하는 것이다. 그리고 다시 나갈 때는 lock을 false로 바꾸고 나가면 된다. 하지만 **내가 들어가서 그냥 무한대로 Critical section을 쓸 수 있기 때문에 bounded waiting조건은 충족되지 않는다.**
    - 2) Swap(xchg)
    - * Swap 역시 test-and-set방법과 마찬가지로 bounded waiting 문제는 해결되지 않는다. Swap 역시 마찬가지로 최초에 false로 초기화된 lock 변수를 가지고 있다. 프로세스가 Critical section에 진입하려고 하면 key = true;로 바꾼 후에 Swap(lock, key)를 수행한다. 그렇게 되면 lock이 true가 되고 key는 false가 된 후 critical section에 진입하게 되고, 나갈 때는 lock을 다시 false로 만들어주면 된다.
* Test-and Set Instruction과 Swap instruction을 간단한 코드로 보면 아래와 같다.
```
///////// Test-and-Set
repeat
    while Test-and-Set(lock) do no-ops;
        Critical section
    lock = false;
        remainder section
until false;

//////// Swap 
do{ /* lock is initially false */
    key = true;
    while(key == true) Swap(lock, key);
        critical section
    lock = false;
        remainder section
}
```
### 3) 두 방식의 문제점
* Software-only solution, Hardware atomic instruction은 몇가지 문제점이 존재한다.
1) **Spinning lock이라는 말처럼 프로세스나 쓰레드가 Critical Section에 접근하지 못하는 상황에서는 계속 while loop를 돌고 있기 때문에 비효율적이다. 이거는 꽤 심각한 문제인데, 이렇게 되면 무한루프를 돌고 있는 쓰레드는 다른 쓰레드에게 CPU 할당을 넘겨주지 않아서 스위칭이 잘 일어나지 못하게 되는 것이다.**
2) 그리고 Critical section이 길면 길수록 Spinning lock의 시간이 길어지게 된다.

---
## 2. High-level Synchronization
* 위에서 살펴본 Software-only solution은 복잡성과 spinlock으로 인한 resource의 낭비가 심하기 때문에 효율적이지 않았다. 조금 더 High-level solution이 필요하게 되었다.
* High-level Synchronization은 크게 두 가지를 목표로 한다.
    * 1) Block waiting processes - Busy Waiting(Spinlock)과 달리 기다리고 있는 프로세스가 사용 가능한 상태로 존재하게 만든다.
    * 2) Critical Section안에 들어가도 Interrupts가 가능하게 되어 중요한 Interrupt에 대해 반응할 수 있게 한다.
* 그렇다면 High-level Synchronization은 어떻게 하는 것인지 알아보자.

---
### 1) Semaphore
* Semaphore는 Dijskstra에 의해 고안된 방법이며, lock 방법처럼 spinlock(busy waiting)을 하지 않게 하고, atomically하게 수행된다.
* semaphore는 크게 두 가지 방법으로 구현할 수 있다.
- **Binary semaphore**는 mutex를 이용해서 무조건 하나의 쓰레드나 프로세스만 critical section에 입장할 수 있게 한다. 따라서 counter값은 처음에 1로 설정된다.
- **Counting semphore**는 2이상의 정수값을 가질 수 있는 semaphore다. counting semaphore는 시스템에서 사용할 수 있는 리소스의 수로 초기화되며, counting semaphore가 0보다 클 때 critical section에 진입할 수 있고, 0이면 프로세스가 signal 함수를 통해 counting semaphore값을 증가시킬 때까지 프로세스는 대기하게 된다.   
* 우선 Semaphore 기법을 어떻게 사용하는지에 대해 아래와 같은 pseudo-code로 이해해보자.
```
wait(S) : while S <= 0 do no-ops;
    S:= S-1;
Signal(S): S:= S+1;

/// Critical Section using semaphore
repeat
    wait(mutex)             // var mutex: semaphore, initially mutex = 1
        critical section
    signal(mutex);
        remainder section
until false;
```
* semaphore 기법은 wait()를 통해 semaphore s가 open될 때까지 다른 프로세스를 **block**하려고 한다. 처음에 semaphore값은 1이기 때문에 프로세스는 critical section에 접근할 수 있게 되고 semaphore값을 1을 빼서 0으로 만든다. 그러면 다른 프로세스들은 semaphore값이 0이기 때문에 block되게 하려는 의도다. 하지만 위의 코드에서는 아직 block이 제대로 걸리지 않았음을 알 수 있다.
```
while S<=0 do no-op;
```
* **위에서 S가 0이 되면 계속 while문 안에 갇혀있기 때문에 spinlock과 비슷한 상태가 되는 것이다.** 따라서 semaphore는 **mutex값과 함께 기다리고 있는 프로세스들에 대해서 List**를 만든다. 아래 코드를 보자. 
```
wait(S): 
    S.value : S.value -1;
    if S.value < 0:
        then bigin
            add this process to S.L;
            block;
            end;
signal(S):
    S.value := S.value + 1
    if S.value <= 0:
        then bigin
            remove a process P from S.L;
            wakeUp(P);
            end;
```
* 만약 프로세스가 Semaphore S를 기다리게 되면 block되고 Semaphore의 대기 Queue에 들어가게 된다. 그리고 안에서 작업하던 녀석이 끝나면 signal operation을 통해 대기 큐에 있던 프로세스를 빼준다. 

* Semaphore는 아래와 같이 작업의 순서를 정해주는 용도로도 사용될 수 있다. 만약 A 작업을 Pi가 수행한 후에 B작업을 Pj 프로세스가 수행하게 하려고 한다고 생각해보자.
<img src = "https://user-images.githubusercontent.com/61929745/114960469-12aab500-9ea2-11eb-95ab-ae8133eed14c.png" width = 300, height = 150>  

* 위처럼 작업 순서를 구성하고, Semaphore값을 처음에 0으로 박아두면 Pj가 아무리 빨리와도 flag값은 0이기 때문에 기다리게 된다.
* 하지만 mutex, semaphore를 사용하여 프로세스를 block 시킬 때 발생하는 문제 중 하나는 **deadlock**문제다. 아래 그림을 보자.
<img src = "https://user-images.githubusercontent.com/61929745/114960670-78973c80-9ea2-11eb-8f34-51a9fecebf44.png" width = 300, height = 150>   

* S와 Q라는 두개의 Semaphore를 이용해서 서로 상대방의 작업이 끝나고 자신의 작업을 하려는 프로세스를 관리한다고 해보자. 그러면 P0 입장에서는 P1이 자신에게 signal(S)를 보내주기를 기다리는데 P1입장에서는 P0가 자신에게 Signal(Q)를 보내주기를 기다리게 된다. 그러면 두 프로세스가 lock에 갇혀서 빠져나오지 못하는 상황이 되는 것이다.   


* semaphore는 high level synchronization으로 block을 이용하여 자원의 낭비를 줄이는 장점이 있었다. 하지만 아래와 같은 단점도 분명 존재한다.
    * - 1) semaphore는 global variable이기 때문에 어디서나 접근할 수 있게 되어 개발자가 잘못 건드리면 이상해진다.
    * - 2) critical section을 관리하는 상황과 프로세스들의 스케줄링에 사용될 수 있기 때문에 통제를 잘 하지 못하면 deadlock과 같은 문제가 생길 수도 있다.

---
### 2) Critical Region
* 위에서 semaphore의 종류를 봤을 때 **Counting semaphore**가 있었다. 이 말은 critical section에 1개 이상의 프로세스나 쓰레드가 들어갈 수 있다는 뜻이다. 그러면 만약에 거기서 프로세스나 쓰레드들이 공유된 자원을 같이 쓰려고 하면?? 또 다시 synchronization issue가 발생하는 것이다.
* 따라서 Critical Region은 ** 공유되는 자원에 대해서 **region** 키워드를 통해서 누가 이걸 쓰고 있나?를 확인하게 해준다. Producer, consumber의 예제를 다시 보자.
```
// Producer
region buffer when count < n
    do begin
        pool[in] := nextp;
        in := in + 1 mod n;
        count := count + 1;
    end;

// Consumer
region buffer when count > 0
    do begin
        nextc := oppl[out];
        out := out + 1 mod n;
        count := count - 1;
    end;
```
* 코드를 보면 region 키워드를 통해서 공유되고 있는 buffer라는 자원에 대해 지금 쓰고 있는지를 먼저 확인하게 한다!
---

